{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color=royalblue size=10>INTRODUÇÃO</font>\n",
    "\n",
    "***\n",
    "- Arquivo\t: notebook.ipynb\n",
    "- Título\t: Exercício 5 e 6 - Disciplina de Redes Neurais Artificiais (DELT/UFMG)\n",
    "- Autor\t    : Gustavo Augusto Ortiz de Oliveira (gstvortiz@hotmail.com) <br> <br> <br>\n",
    "- Descrição: A atividade dessa semana introduz uma arquitetura amplamente conhecida como Multi Layer Perceptron, ou MLP. As MLPs são estruturas de Redes Neurais Artificiais com duas ou mais camadas alimentadas para frente, tipicamente utilizando funções de ativação sigmoidal na camada intermediária. Diferentemente das estruturas apresentadas anteriormente, a rede não apresenta treinamentos a priori na camada escondida, necessitando de um algoritmo para ajuste simultâneo de pesos. O algoritmo mais difundido para o treinamento de uma rede MLP é chamado backpropagation, ele utiliza o conceito da retropropagação do erro da rede para corrigir os pesos da última camada até a primeira.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align = 'center'>\n",
    "    <img src = \"data/mlp.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color=indianred size=10>BACKPROPAGATION</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] A EQUAÇÃO DE AJUSTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar a dedução das equações da retropropagação de erros, vamos utilizar o gradiente descendente em relação à função de erro de saída, conforme Equação 1, em que m é a quantidade de neurônios na camada de saída e k indica que o erro está sendo calculado para cada amostra do conjunto de dados de entrada. Esta notação será omitida por enquanto e será retomada ao final das deduções.\n",
    "\n",
    "\n",
    "#### $$ \\epsilon = \\frac{1}{2}\\sum^m_{j=1}(y_{j}-\\hat{y}_{j})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] CAMADA DE SAÍDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial w_{ij}} = \\frac{\\partial (\\frac{1}{2}\\sum^m_{j=1}(y_{j}-\\hat{y}_{j})^2)}{\\partial w_{ij}} = \\frac{1}{2}\\frac{\\partial}{\\partial w_{ij}}(y_{j}-\\hat{y}_{j})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial w_{ij}} = \\frac{1}{2}2(y_j - \\hat{y}_{j})\\frac{\\partial}{\\partial w_{ij}}(y_j - \\hat{y}_{j}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial w_{ij}} = \\epsilon_j \\frac{\\partial}{\\partial w_{ij}}(y_j - g(u_{j})) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial w_{ij}} = -\\epsilon_j\\frac{\\partial g(u_{j})}{\\partial u_{j}}\\frac{\\partial u_{j}}{\\partial w_{ij}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial w_{ij}} = -\\epsilon_j g'(u_{j})\\frac{\\partial u_{j}}{\\partial w_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial w_{ij}} = -\\delta_j\\frac{\\partial u_{j}}{\\partial w_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial w_{ij}} = -\\delta_j\\frac{\\partial (h(u)*w_j)}{\\partial w_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial w_{ij}} = -\\delta_jh(u_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caminhando no sentido contrário do gradiente, temos:\n",
    "\n",
    "#### $$ \\Delta w_{ij}= \\eta \\delta_jh(u_i)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] CAMADA ESCONDIDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial z_{li}} = \\frac{\\partial (\\frac{1}{2}\\sum^m_{j=1}(y_{j}-\\hat{y}_{j})^2)}{\\partial z_{li}} = \\frac{1}{2}\\frac{\\partial}{\\partial z_{li}}\\sum^m_{j=1}(y_{j}-\\hat{y}_{j})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon_j}{\\partial z_{li}} = \\frac{1}{2}\\frac{\\partial}{\\partial z_{li}}(y_{j}-\\hat{y}_{j})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon_j}{\\partial z_{ij}} = -\\delta_j\\frac{\\partial u_{j}}{\\partial z_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon_j}{\\partial z_{ij}} = - \\delta_{j} \\frac{\\partial (h(u)*w_j)}{\\partial z_{li}} $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### $$ \\frac{\\partial \\epsilon_j}{\\partial z_{ij}} = - \\delta_{j} w_{ij} \\frac{\\partial (h(u_{i}))}{\\partial z_{li}}  $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon_j}{\\partial z_{ij}}  = - \\delta_{j} w_{ij} h'({u_{i}})\\frac{\\partial (x*z_i)}{\\partial z_{li}}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon_j}{\\partial z_{ij}}  = - \\delta_{j} w_{ij} h'({u_{i}})x_l$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $$ \\frac{\\partial \\epsilon}{\\partial z_{li}} = - (\\sum_{j=1}^{m} \\delta_{j} w_{ij}) \\space h'({u_{i}}) \\space x_l$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caminhando no sentindo contrário do gradiente, temos:\n",
    "\n",
    "#### $$ \\Delta z_{li} = \\eta (\\sum_{j=1}^{m} \\delta_{j} w_{ij}) \\space h'({u_{i}}) \\space x_l$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color=seagreen size=10>IMPLEMENTAÇÃO</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] BIBLIOTECAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import datetime\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] FUNÇÕES AUXILIARES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias(m):\n",
    "    m = np.array(m)\n",
    "    if m.ndim > 1:\n",
    "        return np.hstack((m, np.ones((m.shape[0], 1))))\n",
    "    else:\n",
    "        return np.append(m, 1)\n",
    "    \n",
    "def sech2(x):\n",
    "    return 2 / (np.exp(x) + np.exp(-x))**2\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    comp = (y_true.ravel() == y_pred.ravel())\n",
    "    return sum(comp) / len(comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] CLASSE DA REDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayersAdaline:\n",
    "    def __init__(self, p = 100, η = 0.001, nepocas = 150, tol = 0.01):\n",
    "        self.p = p\n",
    "        self.η = η\n",
    "        self.nepocas = nepocas        \n",
    "        self.tol = tol\n",
    "        self.h = np.tanh\n",
    "        self.hx = sech2\n",
    "        self.g = lambda x: x\n",
    "        self.gx = lambda x: 1\n",
    "        self.erros = dict()\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        n, m = X_train.shape[1], 1\n",
    "        self.z = np.random.normal(size = (n + 1, self.p))\n",
    "        self.w = np.random.normal(size = (self.p + 1, m))\n",
    "        self.erros.clear()\n",
    "        for epoca in range(self.nepocas):\n",
    "            for idx in np.random.permutation(len(X_train)):\n",
    "                ui, uj = self.dotLayers(X_train[idx])\n",
    "                e = y_train[idx] - self.g(uj)\n",
    "                δ = e*self.gx(uj)\n",
    "\n",
    "                for i in range(self.p):\n",
    "                    for j in range(m):\n",
    "                        self.w[i][j] += self.η*δ[j]*self.h(ui[i])\n",
    "                \n",
    "                for l in range(n):\n",
    "                    for i in range(self.p):\n",
    "                        self.z[l][i] += self.η*sum([δ[j]*self.w[i][j] for j in range(m)]) * self.hx(ui)[i] * X_train[idx][l]\n",
    "                self.erros[epoca] = [e[0]**2] if epoca not in self.erros else self.erros[epoca] + [e[0]**2]\n",
    "\n",
    "    def dotLayers(self, X):\n",
    "        ui = np.dot(bias(X), self.z)\n",
    "        uj = np.dot(bias(self.h(ui)), self.w)\n",
    "        return ui, uj\n",
    "\n",
    "    def predict(self, X, f = np.round):\n",
    "        _, uj = self.dotLayers(X)\n",
    "        return f(self.g(uj))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4] CLASSE PARA VISUALIZAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GIF():\n",
    "    def __init__(self, folder = 'data/img'):\n",
    "        self.folder = folder\n",
    "\n",
    "    def Preparar(self):\n",
    "        if os.path.exists(self.folder):\n",
    "            shutil.rmtree(self.folder)\n",
    "        os.mkdir(self.folder)\n",
    "    \n",
    "    def FileNames(self):\n",
    "        arquivos_info = []\n",
    "        for nome_imagem in os.listdir(self.folder):\n",
    "            caminho_completo = os.path.join(self.folder, nome_imagem)\n",
    "            data_criacao = datetime.datetime.fromtimestamp(os.path.getctime(caminho_completo))\n",
    "            arquivos_info.append((caminho_completo, data_criacao))\n",
    "        arquivos_info.sort(key=lambda x: x[1])\n",
    "        return np.array(arquivos_info)[:, 0]\n",
    "    \n",
    "    def Make(self, path = 'data'):\n",
    "        imagens = []\n",
    "        for caminho in self.FileNames():\n",
    "            imagem = Image.open(caminho)\n",
    "            imagens.append(imagem)\n",
    "        imagens[0].save(f'{path}/gif.gif', save_all=True, append_images=imagens[1:], duration=400, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5] FUNÇÃO PARA SUPERFÍCIE DE SEPARAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Grid(Neuronio, ax, alpha = 0.5, palette = 'plasma'):\n",
    "    eixo_x = np.linspace(ax.get_xlim()[0], ax.get_xlim()[1], 200)\n",
    "    eixo_y = np.linspace(ax.get_ylim()[0], ax.get_ylim()[1], 200)\n",
    "    xx, yy = np.meshgrid(eixo_x, eixo_y)\n",
    "    pontos = np.column_stack((xx.ravel(), yy.ravel()))\n",
    "    labels_pred = Neuronio.predict(pontos).reshape(xx.shape).round(2)\n",
    "    ax.contourf(xx, yy, labels_pred, alpha = alpha, cmap = palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color=seagreen size=10>ATIVIDADE 5</font>\n",
    "\n",
    "[ENUNCIADO]\n",
    "\n",
    "<em>Para observar que o MLP é capaz de aproximar qualquer função contínua, deve realizar a\n",
    "regressão de um ciclo de uma senoide MLP com backpropagation. A função de ativação\n",
    "da camada de saída deve ser linear, e devem haver 3 ou mais neurônios na camada escondida.</em>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIF().Preparar()\n",
    "metricas = []\n",
    "for p in range(2, 101, 2):\n",
    "    X = np.array([np.linspace(0, 2*np.pi, 200)]).T\n",
    "    y = np.sin(X.ravel()+np.random.normal(scale=0.25, size=200))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "    Rede = TwoLayersAdaline(p = p)\n",
    "    Rede.fit(X_train, y_train)\n",
    "    y_pred = Rede.predict(X_test, f = lambda x: x)\n",
    "\n",
    "    metricas.append([r2_score(y_test, y_pred), 1 - mean_squared_error(y_test, y_pred)])\n",
    "    df_metricas = lambda x: pd.DataFrame(metricas).iloc[:, x].round(2)\n",
    "    labelr2  = f'R²        (x̄: {df_metricas(0).mean():.2f}, σ: {df_metricas(0).std():.2f})'\n",
    "    labelmse = f'1 - MSE (x̄: {df_metricas(1).mean():.2f}, σ: {df_metricas(1).std():.2f})  '\n",
    "    fig, axs = plt.subplots(1, 2, figsize = (14, 6))\n",
    "    fig.suptitle(f'MultiLayer Perceptron: Aproximação da função sen(x) com {p} neurônios', fontsize = 16, y = 1.01)\n",
    "    sns.scatterplot(x = X_train.ravel(), y = y_train.ravel(), label = 'Dados de Treino', ax = axs[0], s = 15)\n",
    "    sns.scatterplot(x = X_test.ravel(), y = y_test.ravel(), label = 'Dados de Teste', ax = axs[0], s = 15)\n",
    "    sns.lineplot(x = X_test.ravel(), y = y_pred.ravel(), label = 'Aproximação', color = 'forestgreen', ax = axs[0])\n",
    "    sns.lineplot(x = [2*i+2 for i in range(len(metricas))], y = df_metricas(0), label = labelr2, ax = axs[1])\n",
    "    sns.lineplot(x = [2*i+2 for i in range(len(metricas))], y = df_metricas(1), label = labelmse, ax = axs[1])\n",
    "    axs[0].set_title('Resultado da Aproximação')\n",
    "    axs[0].set_ylim(-1.5, 1.5)\n",
    "    axs[0].set_xlabel('x1')\n",
    "    axs[0].set_ylabel('y1')\n",
    "    axs[1].set_title('Análise de Métricas')\n",
    "    axs[1].set_ylim(0, 1.05)\n",
    "    axs[1].set_xlabel('Quantidade de Neurônios')\n",
    "    axs[1].set_ylabel('Métricas')\n",
    "    axs[1].legend(loc='lower right')\n",
    "    axs[1].set_xlim(0, p + 2)\n",
    "    plt.savefig(f'data/img/{p}.png', bbox_inches = 'tight')\n",
    "    plt.close()\n",
    "    \n",
    "GIF().Make()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align = 'center'>\n",
    "    <img src = \"data/gif.gif\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <font color=seagreen size=10>ATIVIDADE 6</font>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] PARTE 1\n",
    "\n",
    "***\n",
    "[ENUNCIADO]\n",
    "<em>Utilizando a mesma rede MLP que você implementou para resolver o problema da aproximação da função senoidal, resolva o problema de classificação do OU-Exclusivo (XOR) mostrado na Figura 1. As classes devem ser como mostradas na figura (alternadas). O aluno deve:\n",
    "\n",
    "1. Criar os dados de treinamento e teste.\n",
    "2. Treinar uma RNA com uma camada escondida de 3 ou mais neurônios com função de ativação tangente hiperbólica e um neurônio de saída com função de ativação linear.\n",
    "3. Testar o modelo obtido com os dados de teste (separe 30% dos dados aleatoriamente para teste). Lembre-se de definir um limiar para a classificação da saída.\n",
    "4. Plotar a superfície de separação no espaço de entrada.\n",
    "5. Calcular a acurácia de treino e teste. </em>\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('data/xor.csv')[['x1', 'x2', 'y']]\n",
    "X = dados.drop(['y'], axis = 1).values\n",
    "y = dados['y'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)\n",
    "Rede = TwoLayersAdaline(p=100, nepocas=500)\n",
    "Rede.fit(X_train, y_train)\n",
    "y_pred = Rede.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (12, 4))\n",
    "fig.suptitle('Rede MLP: Problema XOR com 100 Neurônios', y = 1.03)\n",
    "\n",
    "sns.scatterplot(x = X_train[:, 0], y = X_train[:, 1], hue = y_train, palette='plasma', ax = axs[0])\n",
    "axs[0].set_title('Dados de Treino')\n",
    "\n",
    "sns.scatterplot(x = X_test[:, 0], y = X_test[:, 1], hue = y_test, palette='plasma', ax = axs[1])\n",
    "axs[1].set_title(f'Dados de Teste (Acurácia: {score(y_test, y_pred):.2f})')\n",
    "Grid(Rede, axs[1])\n",
    "\n",
    "for ax in axs.ravel(): \n",
    "    ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align = 'center'>\n",
    "    <img src = \"data/Ex6-1.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] PARTE 2\n",
    "***\n",
    "[ENUNCIADO]\n",
    "\n",
    "<em>Aplique esta mesma rede ao problema do Câncer de mama (Breast Cancer). Esta base de dados pode ser carregada do pacote mlbench. Esta base de dados possui 9 variáveis de entrada, uma variável de saída com a classificação das 699 amostras em maligno e benigno. Nesta atividade, o aluno irá realizar o treinamento da MLP para separar as classes e avaliar o desempenho do mesmo. O aluno deverá então:\n",
    "\n",
    "Carregar os dados e armazená-los. Estes dados devem receber um tratamento inicial para eliminação dos dados faltantes. Os dados faltantes são representados pelo string NaN.\n",
    "\n",
    "1. Rotular as amostras das classes com o valor de 0 (maligno) e 1 (benigno).\n",
    "\n",
    "2. Selecionar aleatoriamente 70% das amostras para o conjunto de treinamento e 30% para o conjunto de teste, para cada uma das duas classes.\n",
    "\n",
    "3. Utilizar as amostras de treinamento para fazer o treinamento da MLP.\n",
    "\n",
    "4. Aplicar o modelo treinado na classificação do conjunto de testes.\n",
    "\n",
    "5. Calcular o erro percentual. (O erro é dado pelo número de amostras de teste classificadas de forma errada)\n",
    "\n",
    "6. Criar um loop para repetir 10 vezes os itens 2-6 (Validação cruzada com 10 folds), armazenando o valor do erro percentual do item \n",
    "\n",
    "7. Calcular a acurácia média e seu desvio padrão.</em>\n",
    "***\n",
    "Nota: por estar realizando em Python, tive de buscar a base na internet, a partir do link: https://archive.ics.uci.edu/dataset/15/breast+cancer+wisconsin+original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv('data/breast-cancer-wisconsin.csv')\n",
    "dados = dados.replace('?', np.nan).dropna().astype(int)\n",
    "dados['Class'] = dados['Class'].map({2: 1, 4: 0})\n",
    "\n",
    "dados = dados.sample(frac=1)\n",
    "X = dados.drop('Class', axis = 1).values\n",
    "y = dados['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erros = dict()\n",
    "for p in range(5, 25, 5):\n",
    "    erros[p] = dict()\n",
    "    for fold, (train_idx, test_idx) in enumerate(KFold(n_splits=10).split(X)):\n",
    "        X_train, X_test, y_train, y_test = X[train_idx], X[test_idx], y[train_idx] , y[test_idx] \n",
    "        Rede = TwoLayersAdaline(p=p, nepocas=200)\n",
    "        Rede.fit(X_train, y_train)\n",
    "        y_pred = Rede.predict(X_test)\n",
    "        erros[p][fold] = score(y_test, y_pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(erros).iloc[:, ::-1]\n",
    "ax = sns.boxplot(df, orient = 'h')\n",
    "ax.figure.set_size_inches(12, 7)\n",
    "ax.set_title('Desempenho da Rede (10 Folds)', fontsize = 18)\n",
    "ax.set_xlabel('Acurácia (%)', fontsize = 16)\n",
    "ax.set_ylabel('Quantidade de Neurônios', fontsize = 16)\n",
    "ax.set_xlim(0, 100)\n",
    "for i in range(4):\n",
    "    ax.text(x = 10, y = i + 0.07, s = f' (Média: {df.mean().iloc[i]:.2f}, Desvio Padrão: {df.std().iloc[i]:.2f})', va ='bottom', ha= 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align = 'center'>\n",
    "    <img src = \"data/Ex6-2.png\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
